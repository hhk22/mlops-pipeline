{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJbixH8Qb1zd",
        "outputId": "5ed02360-0894-4540-b6de-efdd4de73a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-cloud-aiplatform kfp google-cloud-pipeline-components"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud.aiplatform import gapic as aiplatform_gapic\n",
        "from kfp.v2 import compiler\n",
        "from kfp.v2.dsl import pipeline, component\n",
        "from google.cloud import storage, aiplatform\n",
        "from google.oauth2 import service_account"
      ],
      "metadata": {
        "id": "BQvoRFj9c7l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"mlops-pipeline-427209\"\n",
        "REGION = \"us-central1\"\n",
        "BUCKET_NAME = \"mlops_vertexai_hh\""
      ],
      "metadata": {
        "id": "CgxJZ9NIdsSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PIPELINE_ROOT = f\"gs://{BUCKET_NAME}/pipeline_root\"\n",
        "BUCKET_PATH = f\"gs://{BUCKET_NAME}\"\n",
        "MODEL_DIR = f\"{BUCKET_PATH}/model\"\n",
        "DATA_DIR = f\"{BUCKET_PATH}/data\""
      ],
      "metadata": {
        "id": "Hp7sGybOeKrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credentials = service_account.Credentials.from_service_account_file(\"credentials.json\")"
      ],
      "metadata": {
        "id": "vChtd6T8eSC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION, credentials=credentials)"
      ],
      "metadata": {
        "id": "v60ZTrAigD0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth login --cred-file=credentials.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Umz55Vi3gEtT",
        "outputId": "b591684e-063e-4f3a-eaeb-0775ca04a8b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are already authenticated with \n",
            "'1048017730256-compute@developer.gserviceaccount.com'.\n",
            "Do you wish to proceed and overwrite existing credentials?\n",
            "\n",
            "Do you want to continue (Y/n)?  Y\n",
            "\n",
            "\n",
            "Authenticated with service account credentials for: [1048017730256-compute@developer.gserviceaccount.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@component(base_image=\"python:3.11\", packages_to_install=[\"google-cloud-bigquery\"])\n",
        "def export_data_to_gcs(\n",
        "    project_id: str, dataset_id: str, table_id: str, gcs_bucket_path: str\n",
        ") -> str:\n",
        "    from google.cloud import bigquery\n",
        "\n",
        "    client = bigquery.Client(project=project_id)\n",
        "    destination_uri = f\"{gcs_bucket_path}/netflix_data_*.csv\"\n",
        "    dataset_ref = bigquery.DatasetReference(project_id, dataset_id)\n",
        "    table_ref = dataset_ref.table(table_id)\n",
        "\n",
        "    extract_job = client.extract_table(table_ref, destination_uri, location=\"US\")\n",
        "    extract_job.result()\n",
        "\n",
        "    print(f\"Data exported to {destination_uri}\")\n",
        "    return destination_uri"
      ],
      "metadata": {
        "id": "PtOg6fB2gJr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@component(\n",
        "    base_image=\"python:3.11\",\n",
        "    packages_to_install=[\n",
        "        \"torch\",\n",
        "        \"torchvision\",\n",
        "        \"numpy\",\n",
        "        \"pandas\",\n",
        "        \"gcsfs\",\n",
        "        \"google-cloud-storage\",\n",
        "    ],\n",
        ")\n",
        "def train_model(project_id: str, gcs_bucket_path: str, data_path: str) -> str:\n",
        "    from google.cloud import storage\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    import torch.nn.functional as F\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import gcsfs\n",
        "    from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "    class NetflixDataset(Dataset):\n",
        "        def __init__(self, data):\n",
        "            self.users = torch.tensor(data[\"User_Id\"].values.astype(np.int32))\n",
        "            self.movies = torch.tensor(data[\"Movie_Id\"].values.astype(np.int32))\n",
        "            self.ratings = torch.tensor(data[\"Rating\"].values.astype(np.float32))\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.users)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            return (\n",
        "                self.users[idx].to(device),\n",
        "                self.movies[idx].to(device),\n",
        "                self.ratings[idx].to(device),\n",
        "            )\n",
        "\n",
        "    class RecommenderNN(nn.Module):\n",
        "        def __init__(self, num_users, num_movies, emb_size=100):\n",
        "            super(RecommenderNN, self).__init__()\n",
        "            self.user_emb = nn.Embedding(num_users + 1, emb_size)\n",
        "            self.movie_emb = nn.Embedding(num_movies + 1, emb_size)\n",
        "            self.fc1 = nn.Linear(2 * emb_size, 256)\n",
        "            self.fc2 = nn.Linear(256, 128)\n",
        "            self.fc3 = nn.Linear(128, 64)\n",
        "            self.fc4 = nn.Linear(64, 1)\n",
        "\n",
        "        def forward(self, user, movie):\n",
        "            user_emb = self.user_emb(user)\n",
        "            movie_emb = self.movie_emb(movie)\n",
        "            x = torch.cat([user_emb, movie_emb], dim=1)\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = F.relu(self.fc2(x))\n",
        "            x = F.relu(self.fc3(x))\n",
        "            return self.fc4(x).squeeze()\n",
        "\n",
        "    def calculate_accuracy(y_pred, y_true):\n",
        "        y_pred_rounded = torch.round(y_pred)\n",
        "        correct_predictions = (y_pred_rounded == y_true).float().sum()\n",
        "        accuracy = correct_predictions / y_true.shape[0]\n",
        "        return accuracy.item()\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = RecommenderNN(num_users=2649429, num_movies=17770).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    client = storage.Client()\n",
        "    fs = gcsfs.GCSFileSystem(project=project_id)\n",
        "    files = fs.glob(data_path)\n",
        "    data = pd.concat([pd.read_csv(fs.open(file_)) for file_ in files], ignore_index=True)\n",
        "\n",
        "    dataset = NetflixDataset(data)\n",
        "    data_loader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_accuracy = 0\n",
        "        count_batches = 0\n",
        "\n",
        "        for users, movies, ratings in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(users, movies)\n",
        "            loss = criterion(outputs, ratings)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            accuracy = calculate_accuracy(outputs, ratings)\n",
        "            total_loss += loss.item()\n",
        "            total_accuracy += accuracy\n",
        "            count_batches += 1\n",
        "\n",
        "        avg_loss = total_loss / count_batches\n",
        "        avg_accuracy = total_accuracy / count_batches\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Loss = {avg_loss}, Accuracy = {avg_accuracy}\")\n",
        "\n",
        "    model_path = f\"{gcs_bucket_path}/model.pth\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    return model_path"
      ],
      "metadata": {
        "id": "GxJYUPKOtyAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@component(base_image=\"python:3.11\")\n",
        "def deploy_model_op(project_id: str, model_path: str):\n",
        "    from google.cloud import aiplatform\n",
        "\n",
        "    model = aiplatform.Model.upload(\n",
        "        project=project_id,\n",
        "        display_name=\"netflix-recommender\",\n",
        "        artifact_uri=model_path,\n",
        "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu.2-1:latest\",\n",
        "    )\n",
        "    endpoint = model.deploy(\n",
        "        machine_type=\"n1-standard-2\",\n",
        "        min_replica_count=1,\n",
        "        max_replica_count=2\n",
        "    )"
      ],
      "metadata": {
        "id": "52o_vjHot2MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@pipeline(name=\"netflix-recommender-pipeline\", pipeline_root=PIPELINE_ROOT)\n",
        "def netflix_recommender_pipeline(project_id: str, gcs_bucket_path: str):\n",
        "    export_op = export_data_to_gcs(\n",
        "        project_id=project_id,\n",
        "        dataset_id=\"dataflow\",\n",
        "        table_id=\"netflix_prize_data\",\n",
        "        gcs_bucket_path=gcs_bucket_path\n",
        "    )\n",
        "    train_op = (\n",
        "        train_model(\n",
        "            project_id=project_id,\n",
        "            gcs_bucket_path=gcs_bucket_path,\n",
        "            data_path=export_op.output,\n",
        "        )\n",
        "        .set_memory_limit(\"32Gi\")\n",
        "        # .add_node_selector_constraint(\"NVIDIA_TESLA_T4\")\n",
        "    )\n",
        "    deploy_model_op(project_id=project_id, model_path=train_op.output)"
      ],
      "metadata": {
        "id": "TM8sPMNft3xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compiler.Compiler().compile(\n",
        "    pipeline_func=netflix_recommender_pipeline,\n",
        "    package_path=\"pipeline_job.yaml\",\n",
        ")\n",
        "\n",
        "job = aiplatform.PipelineJob(\n",
        "    display_name=\"netflix_recommender_pipeline\",\n",
        "    template_path=\"pipeline_job.yaml\",\n",
        "    pipeline_root=PIPELINE_ROOT,\n",
        "    parameter_values={\"project_id\": PROJECT_ID, \"gcs_bucket_path\": BUCKET_PATH},\n",
        ")\n",
        "\n",
        "job.submit(\n",
        "    service_account=\"1048017730256-compute@developer.gserviceaccount.com\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUmAvP3ahLpW",
        "outputId": "382e893d-6249-4ff2-9fc9-4e9cef90beb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/1048017730256/locations/us-central1/pipelineJobs/netflix-recommender-pipeline-20240623061045\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/1048017730256/locations/us-central1/pipelineJobs/netflix-recommender-pipeline-20240623061045')\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
            "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/netflix-recommender-pipeline-20240623061045?project=1048017730256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c90jVwZti33S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}